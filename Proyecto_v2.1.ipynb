{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3204d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El recurso 'wordnet' de NLTK no se encontró. Descargando...\n",
      "Descarga de 'wordnet' completada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabricio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# --- Descargar recursos de NLTK si no los tienes ---\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"El recurso 'stopwords' de NLTK no se encontró. Descargando...\")\n",
    "    nltk.download('stopwords')\n",
    "    print(\"Descarga de 'stopwords' completada.\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    print(\"El recurso 'wordnet' de NLTK no se encontró. Descargando...\")\n",
    "    nltk.download('wordnet')\n",
    "    print(\"Descarga de 'wordnet' completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e0e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clase para preprocesamiento de texto ---\n",
    "class PreprocesadorTexto:\n",
    "    def __init__(self):\n",
    "        self.stop_words_en = set(stopwords.words('english'))\n",
    "        self.stop_words_es = set(stopwords.words('spanish'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.embedding_dim = 0  # Sin Sentence-BERT por simplicidad\n",
    "        self.medical_translations = {\n",
    "            'dolor de pecho': 'chest pain',\n",
    "            'dolor de cabeza': 'headache',\n",
    "            'fiebre': 'fever',\n",
    "            'tos': 'cough',\n",
    "            'vómito': 'vomiting',\n",
    "            'mareo': 'dizziness',\n",
    "            'dolor abdominal': 'abdominal pain',\n",
    "            'diarrea': 'diarrhea',\n",
    "            'palpitaciones': 'palpitations',\n",
    "            'dolor de garganta': 'sore throat',\n",
    "            'dolor muscular': 'muscle pain',\n",
    "            'dolor lumbar': 'low back pain',\n",
    "            'dolor de espalda': 'back pain',\n",
    "            'dolor de estómago': 'stomach pain',\n",
    "            'náuseas': 'nausea',\n",
    "            'estreñimiento': 'constipation',\n",
    "            'falta de aire': 'shortness of breath',\n",
    "            'opresión en el pecho': 'chest tightness',\n",
    "            'pérdida de conocimiento': 'loss of consciousness',\n",
    "            'desmayo': 'fainting',\n",
    "            'sudoración': 'sweating',\n",
    "            'escalofríos': 'chills',\n",
    "            'fatiga': 'fatigue',\n",
    "            'cansancio': 'tiredness',\n",
    "            'debilidad': 'weakness',\n",
    "            'insomnio': 'insomnia',\n",
    "            'ansiedad': 'anxiety',\n",
    "            'depresión': 'depression',\n",
    "            'dolor articular': 'joint pain',\n",
    "            'dolor de pierna': 'leg pain',\n",
    "            'dolor de brazo': 'arm pain',\n",
    "            'dolor de cuello': 'neck pain',\n",
    "            'dolor de oído': 'ear pain',\n",
    "            'dolor ocular': 'eye pain',\n",
    "            'sangrado': 'bleeding',\n",
    "            'picazón': 'itching',\n",
    "            'erupción': 'rash',\n",
    "            'inflamación': 'swelling',\n",
    "        }\n",
    "\n",
    "    def detectar_idioma(self, texto):\n",
    "        spanish_words = sum(1 for word in texto.split() if word.lower() in self.stop_words_es)\n",
    "        english_words = sum(1 for word in texto.split() if word.lower() in self.stop_words_en)\n",
    "        return 'spanish' if spanish_words > english_words else 'english'\n",
    "\n",
    "    def traducir_texto(self, texto, idioma):\n",
    "        if idioma == 'spanish':\n",
    "            for es, en in self.medical_translations.items():\n",
    "                texto = texto.replace(es, en)\n",
    "            return texto\n",
    "        return texto\n",
    "\n",
    "    def limpiar_texto(self, texto):\n",
    "        texto = texto.lower()\n",
    "        texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "        palabras = texto.split()\n",
    "        palabras = [self.lemmatizer.lemmatize(word) for word in palabras if word not in self.stop_words_en]\n",
    "        return ' '.join(palabras)\n",
    "\n",
    "    def procesar_texto_completo(self, texto):\n",
    "        idioma = self.detectar_idioma(texto)\n",
    "        texto_traducido = self.traducir_texto(texto, idioma)\n",
    "        texto_limpio = self.limpiar_texto(texto_traducido)\n",
    "        return {\n",
    "            'idioma_detectado': idioma,\n",
    "            'texto_traducido': texto_traducido,\n",
    "            'texto_limpio': texto_limpio,\n",
    "            'tiene_embeddings': False,  # Sin embeddings por ahora\n",
    "            'dimension_embeddings': self.embedding_dim\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711b662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cargando datasets...\n",
      "\n",
      "Columnas de Independent_Medical_Reviews.csv:\n",
      "Index(['Reference ID', 'Report Year', 'Diagnosis Category',\n",
      "       'Diagnosis Sub Category', 'Treatment Category',\n",
      "       'Treatment Sub Category', 'Determination', 'Type', 'Age Range',\n",
      "       'Patient Gender', 'Findings'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeras 5 filas de Independent_Medical_Reviews.csv:\n",
      "  Reference ID  Report Year      Diagnosis Category Diagnosis Sub Category  \\\n",
      "0   MN16-22639         2016              Infectious              Hepatitis   \n",
      "1   MN16-22638         2016                  Mental        Eating Disorder   \n",
      "2   MN16-22637         2016         Autism Spectrum         Autism-PDD-NOS   \n",
      "3   EI16-22636         2016  Prevention/Good Health                    NaN   \n",
      "4    EI06-5319         2006     Cardiac/Circulatory                    NaN   \n",
      "\n",
      "                          Treatment Category  \\\n",
      "0                Pharmacy/Prescription Drugs   \n",
      "1                    Mental Health Treatment   \n",
      "2                   Autism Related Treatment   \n",
      "3  Diagnostic Imaging, Screening and Testing   \n",
      "4                            Cardio Vascular   \n",
      "\n",
      "                     Treatment Sub Category  \\\n",
      "0                               Anti-virals   \n",
      "1  Residential Treatment Center - Admission   \n",
      "2                            Speech Therapy   \n",
      "3                               Mammography   \n",
      "4                                       NaN   \n",
      "\n",
      "                        Determination                          Type Age Range  \\\n",
      "0  Overturned Decision of Health Plan             Medical Necessity     41-50   \n",
      "1      Upheld Decision of Health Plan             Medical Necessity     21-30   \n",
      "2      Upheld Decision of Health Plan             Medical Necessity      0-10   \n",
      "3  Overturned Decision of Health Plan  Experimental/Investigational       65+   \n",
      "4      Upheld Decision of Health Plan  Experimental/Investigational     51-64   \n",
      "\n",
      "  Patient Gender                                           Findings  \n",
      "0           Male  Nature of Statutory Criteria/Case Summary: An ...  \n",
      "1         Female  Nature of Statutory Criteria/Case Summary:  An...  \n",
      "2         Female  Nature of Statutory Criteria/Case Summary:  Th...  \n",
      "3         Female  Nature of Statutory Criteria/Case Summary: An ...  \n",
      "4           Male  Physician 1: The patient is a 62-year-old male...  \n",
      "\n",
      "Columnas de processed_medical_data.csv:\n",
      "Index(['symptoms', 'diagnosis', 'original_diagnosis', 'admission_type',\n",
      "       'category'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeras 5 filas de processed_medical_data.csv:\n",
      "                                            symptoms         diagnosis  \\\n",
      "0  sleep with acute shortness of breath and cough...    Cardiovascular   \n",
      "1  l movement he denies fevers chills nausea if y...  Gastrointestinal   \n",
      "2  fevers chills pain with urination fevers chill...         Infection   \n",
      "3  ion denies chest pain chest pressure palpitati...       Respiratory   \n",
      "4  the cause of your initial vomiting and blood a...    Upper Gi Bleed   \n",
      "\n",
      "                              original_diagnosis admission_type  \\\n",
      "0   RESPIRATORY FAILURE;CONGESTIVE HEART FAILURE      EMERGENCY   \n",
      "1                                 ABDOMINAL PAIN      EMERGENCY   \n",
      "2         URINARY TRACT INFECTION;PYELONEPHRITIS      EMERGENCY   \n",
      "3                                        DYSPNEA      EMERGENCY   \n",
      "4                                 UPPER GI BLEED      EMERGENCY   \n",
      "\n",
      "            category  \n",
      "0  Discharge summary  \n",
      "1  Discharge summary  \n",
      "2  Discharge summary  \n",
      "3  Discharge summary  \n",
      "4  Discharge summary  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar los datos ---\n",
    "print(\"🔄 Cargando datasets...\")\n",
    "try:\n",
    "    df_reviews = pd.read_csv('datos/Independent_Medical_Reviews.csv')\n",
    "    print(\"\\nColumnas de Independent_Medical_Reviews.csv:\")\n",
    "    print(df_reviews.columns)\n",
    "    print(\"\\nPrimeras 5 filas de Independent_Medical_Reviews.csv:\")\n",
    "    print(df_reviews.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Independent_Medical_Reviews.csv no encontrado.\")\n",
    "    df_reviews = None\n",
    "\n",
    "try:\n",
    "    df_processed = pd.read_csv('datos/processed_medical_data.csv')\n",
    "    print(\"\\nColumnas de processed_medical_data.csv:\")\n",
    "    print(df_processed.columns)\n",
    "    print(\"\\nPrimeras 5 filas de processed_medical_data.csv:\")\n",
    "    print(df_processed.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: processed_medical_data.csv no encontrado.\")\n",
    "    df_processed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af97b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Normalizando y combinando datasets...\n",
      "✅ Añadido 19166 filas de Independent_Medical_Reviews.csv\n",
      "✅ Añadido 446 filas de processed_medical_data.csv\n",
      "\n",
      "✅ Dataset combinado creado: 19612 filas\n",
      "Columnas combinadas: ['text_features', 'target_disease', 'age_feature', 'gender_feature']\n",
      "Top 10 diagnósticos:\n",
      "target_disease\n",
      "Orthopedic/ Musculoskeletal              3468\n",
      "Mental                                   2511\n",
      "Cancer                                   1678\n",
      "Central Nervous System/ Neuromuscular    1663\n",
      "Infectious                               1058\n",
      "Cardiac/Circulatory                       964\n",
      "Morbid Obesity                            823\n",
      "OB-Gyn/ Pregnancy                         799\n",
      "Endocrine/ Metabolic                      779\n",
      "Digestive System/ Gastrointestinal        757\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#--- 2. Normalización y combinación de datasets ---\n",
    "print(\"\\n🔧 Normalizando y combinando datasets...\")\n",
    "def normalizar_edad(df, columna_edad):\n",
    "    edad_mapping = {\n",
    "        '0': '0-10', '1': '0-10', '2': '0-10', '3': '0-10', '4': '0-10', '5': '0-10',\n",
    "        '6': '0-10', '7': '0-10', '8': '0-10', '9': '0-10', '10': '0-10',\n",
    "        '11': '11-17', '12': '11-17', '13': '11-17', '14': '11-17', '15': '11-17',\n",
    "        '16': '11-17', '17': '11-17', '18-30': '18-30', '31-40': '31-40',\n",
    "        '41-50': '41-50', '51-64': '51-64', '65+': '65+', 'Unknown': 'Unknown'\n",
    "    }\n",
    "    return df[columna_edad].astype(str).map(edad_mapping).fillna('Unknown')\n",
    "\n",
    "def normalizar_genero(df, columna_genero):\n",
    "    genero_mapping = {\n",
    "        'M': 'Male', 'Male': 'Male', 'MALE': 'Male', 'male': 'Male',\n",
    "        'F': 'Female', 'Female': 'Female', 'FEMALE': 'Female', 'female': 'Female',\n",
    "        'Unknown': 'Unknown', 'U': 'Unknown', 'Other': 'Unknown'\n",
    "    }\n",
    "    return df[columna_genero].astype(str).map(genero_mapping).fillna('Unknown')\n",
    "\n",
    "# Preparar datasets\n",
    "combined_df = pd.DataFrame()\n",
    "preprocesador = PreprocesadorTexto()\n",
    "\n",
    "if df_reviews is not None:\n",
    "    df_reviews_temp = df_reviews[['Findings', 'Diagnosis Category', 'Age Range', 'Patient Gender']].copy()\n",
    "    df_reviews_temp = df_reviews_temp.dropna(subset=['Findings', 'Diagnosis Category'])\n",
    "    df_reviews_temp.rename(columns={\n",
    "        'Findings': 'text_features',\n",
    "        'Diagnosis Category': 'target_disease',\n",
    "        'Age Range': 'age_feature',\n",
    "        'Patient Gender': 'gender_feature'\n",
    "    }, inplace=True)\n",
    "    df_reviews_temp['age_feature'] = normalizar_edad(df_reviews_temp, 'age_feature')\n",
    "    df_reviews_temp['gender_feature'] = normalizar_genero(df_reviews_temp, 'gender_feature')\n",
    "    combined_df = pd.concat([combined_df, df_reviews_temp], ignore_index=True)\n",
    "    print(f\"✅ Añadido {len(df_reviews_temp)} filas de Independent_Medical_Reviews.csv\")\n",
    "\n",
    "if df_processed is not None:\n",
    "    df_processed_temp = df_processed[['symptoms', 'diagnosis']].copy()\n",
    "    df_processed_temp = df_processed_temp.dropna(subset=['symptoms', 'diagnosis'])\n",
    "    df_processed_temp.rename(columns={\n",
    "        'symptoms': 'text_features',\n",
    "        'diagnosis': 'target_disease'\n",
    "    }, inplace=True)\n",
    "    df_processed_temp['age_feature'] = 'Unknown'\n",
    "    df_processed_temp['gender_feature'] = 'Unknown'\n",
    "    combined_df = pd.concat([combined_df, df_processed_temp], ignore_index=True)\n",
    "    print(f\"✅ Añadido {len(df_processed_temp)} filas de processed_medical_data.csv\")\n",
    "\n",
    "if combined_df.empty:\n",
    "    print(\"❌ Error: No se pudo crear un DataFrame combinado válido.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n✅ Dataset combinado creado: {len(combined_df)} filas\")\n",
    "print(f\"Columnas combinadas: {combined_df.columns.tolist()}\")\n",
    "print(\"Top 10 diagnósticos:\")\n",
    "print(combined_df['target_disease'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5672db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧹 Preprocesando datos...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Preprocesamiento de datos ---\n",
    "print(\"\\n🧹 Preprocesando datos...\")\n",
    "combined_df['text_features'] = combined_df['text_features'].apply(\n",
    "    lambda x: preprocesador.procesar_texto_completo(x)['texto_limpio'] if isinstance(x, str) else ''\n",
    ")\n",
    "\n",
    "# Codificar variables categóricas\n",
    "age_encoder = LabelEncoder()\n",
    "gender_encoder = LabelEncoder()\n",
    "diagnosis_encoder = LabelEncoder()\n",
    "\n",
    "combined_df['age_feature'] = age_encoder.fit_transform(combined_df['age_feature'])\n",
    "combined_df['gender_feature'] = gender_encoder.fit_transform(combined_df['gender_feature'])\n",
    "combined_df['target_disease'] = diagnosis_encoder.fit_transform(combined_df['target_disease'])\n",
    "\n",
    "# Vectorización de texto\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(combined_df['text_features'])\n",
    "\n",
    "# Combinar características\n",
    "X_categorical = csr_matrix(combined_df[['age_feature', 'gender_feature']].values)\n",
    "X = hstack([X_tfidf, X_categorical])\n",
    "y = combined_df['target_disease'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Entrenando modelo XGBoost...\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Entrenamiento del modelo ---\n",
    "print(\"\\n🚀 Entrenando modelo XGBoost...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo_v11 = XGBClassifier(random_state=42, n_estimators=100, max_depth=6)\n",
    "modelo_v11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86709ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones y evaluación\n",
    "y_pred = modelo_v11.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Precisión en test: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "clases = diagnosis_encoder.classes_\n",
    "print(\"\\n📋 Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=clases, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd53216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=clases, yticklabels=clases)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Guardado del modelo ---\n",
    "print(\"\\n💾 Guardando modelo v11...\")\n",
    "os.makedirs(\"models/v11_components\", exist_ok=True)\n",
    "\n",
    "with open('models/v11_components/modelo_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_v11, f)\n",
    "with open('models/v11_components/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "with open('models/v11_components/age_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(age_encoder, f)\n",
    "with open('models/v11_components/gender_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(gender_encoder, f)\n",
    "with open('models/v11_components/diagnosis_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(diagnosis_encoder, f)\n",
    "\n",
    "preprocesador_data = {\n",
    "    'medical_translations': preprocesador.medical_translations,\n",
    "    'embedding_dim': preprocesador.embedding_dim,\n",
    "    'stop_words_en': list(preprocesador.stop_words_en),\n",
    "    'stop_words_es': list(preprocesador.stop_words_es),\n",
    "    'lemmatizer_available': preprocesador.lemmatizer is not None\n",
    "}\n",
    "with open('models/v11_components/preprocesador_data.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocesador_data, f)\n",
    "\n",
    "metadata = {\n",
    "    'clases': clases.tolist(),\n",
    "    'precision': test_accuracy,\n",
    "    'fecha': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'num_clases': len(clases),\n",
    "    'embedding_dim': 0,\n",
    "    'version': 'v11'\n",
    "}\n",
    "with open('models/v11_components/metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"✅ Modelo guardado exitosamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
