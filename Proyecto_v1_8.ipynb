{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd42a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando modelo y preprocesadores existentes...\n",
      ">>> Modelo y preprocesadores cargados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 1: CARGAR MODELO Y PREPROCESADORES EXISTENTES ---\n",
    "print(\">>> Cargando modelo y preprocesadores existentes...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cargar modelo entrenado\n",
    "with open('models\\modelo_diagnostico_v6_xgboost.pkl', 'rb') as f:\n",
    "    modelo_existente = pickle.load(f)\n",
    "\n",
    "# Cargar preprocesadores\n",
    "with open('models\\preprocesadores_v6.pkl', 'rb') as f:\n",
    "    preprocesadores = pickle.load(f)\n",
    "    tfidf_vectorizer = preprocesadores['tfidf_vectorizer']\n",
    "    age_encoder = preprocesadores['age_encoder']\n",
    "    gender_encoder = preprocesadores['gender_encoder']\n",
    "    diagnosis_encoder = preprocesadores['diagnosis_encoder']\n",
    "\n",
    "print(\">>> Modelo y preprocesadores cargados exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02c1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando nuevo dataset...\n",
      "Nuevo dataset cargado: 349 filas, 10 columnas\n",
      "\n",
      "Primeras filas del nuevo dataset:\n",
      "       Disease Fever Cough Fatigue Difficulty Breathing  Age  Gender  \\\n",
      "0    Influenza   Yes    No     Yes                  Yes   19  Female   \n",
      "1  Common Cold    No   Yes     Yes                   No   25  Female   \n",
      "2       Eczema    No   Yes     Yes                   No   25  Female   \n",
      "3       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "4       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "\n",
      "  Blood Pressure Cholesterol Level Outcome Variable  \n",
      "0            Low            Normal         Positive  \n",
      "1         Normal            Normal         Negative  \n",
      "2         Normal            Normal         Negative  \n",
      "3         Normal            Normal         Positive  \n",
      "4         Normal            Normal         Positive  \n",
      "\n",
      "Columnas disponibles: ['Disease', 'Fever', 'Cough', 'Fatigue', 'Difficulty Breathing', 'Age', 'Gender', 'Blood Pressure', 'Cholesterol Level', 'Outcome Variable']\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 2: CARGAR Y PREPARAR NUEVOS DATOS ---\n",
    "print(\">>> Cargando nuevo dataset...\")\n",
    "\n",
    "# Cargar el nuevo dataset\n",
    "df_nuevo = pd.read_csv('datos/Disease_symptom_and_patient_profile_dataset.csv')\n",
    "print(f\"Nuevo dataset cargado: {df_nuevo.shape[0]} filas, {df_nuevo.shape[1]} columnas\")\n",
    "\n",
    "# Mostrar primeras filas para entender la estructura\n",
    "print(\"\\nPrimeras filas del nuevo dataset:\")\n",
    "print(df_nuevo.head())\n",
    "\n",
    "# Mostrar columnas disponibles\n",
    "print(f\"\\nColumnas disponibles: {list(df_nuevo.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06381880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Transformando nuevos datos al formato compatible...\n",
      ">>> Datos transformados exitosamente!\n",
      "Ejemplo de texto generado:\n",
      "Patient presents with fever, fatigue, difficulty breathing, hypotension. Age: 19 years old, Gender: Female, Blood pressure: Low, Cholesterol: Normal.\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 3: TRANSFORMAR NUEVOS DATOS AL FORMATO DEL MODELO ORIGINAL ---\n",
    "print(\">>> Transformando nuevos datos al formato compatible...\")\n",
    "\n",
    "# Crear texto de \"findings\" basado en los s√≠ntomas\n",
    "def crear_findings_texto(row):\n",
    "    symptoms = []\n",
    "    if row['Fever'] == 'Yes':\n",
    "        symptoms.append('fever')\n",
    "    if row['Cough'] == 'Yes':\n",
    "        symptoms.append('cough')\n",
    "    if row['Fatigue'] == 'Yes':\n",
    "        symptoms.append('fatigue')\n",
    "    if row['Difficulty Breathing'] == 'Yes':\n",
    "        symptoms.append('difficulty breathing')\n",
    "    \n",
    "    # Agregar informaci√≥n adicional\n",
    "    if row['Blood Pressure'] == 'High':\n",
    "        symptoms.append('hypertension')\n",
    "    elif row['Blood Pressure'] == 'Low':\n",
    "        symptoms.append('hypotension')\n",
    "        \n",
    "    if row['Cholesterol Level'] == 'High':\n",
    "        symptoms.append('high cholesterol')\n",
    "    elif row['Cholesterol Level'] == 'Low':\n",
    "        symptoms.append('low cholesterol')\n",
    "    \n",
    "    # Crear texto descriptivo\n",
    "    findings_text = f\"Patient presents with {', '.join(symptoms)}. \"\n",
    "    findings_text += f\"Age: {row['Age']} years old, Gender: {row['Gender']}, \"\n",
    "    findings_text += f\"Blood pressure: {row['Blood Pressure']}, Cholesterol: {row['Cholesterol Level']}.\"\n",
    "    \n",
    "    return findings_text\n",
    "\n",
    "# Aplicar transformaci√≥n\n",
    "df_nuevo['Findings'] = df_nuevo.apply(crear_findings_texto, axis=1)\n",
    "\n",
    "# Mapear rangos de edad (adaptar al formato original)\n",
    "def mapear_edad(edad):\n",
    "    if edad <= 20:\n",
    "        return \"0-20\"\n",
    "    elif edad <= 30:\n",
    "        return \"21-30\"\n",
    "    elif edad <= 40:\n",
    "        return \"31-40\"\n",
    "    elif edad <= 50:\n",
    "        return \"41-50\"\n",
    "    elif edad <= 60:\n",
    "        return \"51-60\"\n",
    "    elif edad <= 70:\n",
    "        return \"61-70\"\n",
    "    else:\n",
    "        return \"71+\"\n",
    "\n",
    "df_nuevo['Age Range'] = df_nuevo['Age'].apply(mapear_edad)\n",
    "df_nuevo['Patient Gender'] = df_nuevo['Gender']\n",
    "df_nuevo['Diagnosis Category'] = df_nuevo['Disease']\n",
    "\n",
    "print(\">>> Datos transformados exitosamente!\")\n",
    "print(f\"Ejemplo de texto generado:\")\n",
    "print(df_nuevo['Findings'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15144888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Preparando datos para reentrenamiento...\n",
      "Datos limpios: 349 filas\n",
      "Enfermedades √∫nicas en nuevos datos: 116\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 4: PREPARAR DATOS PARA REENTRENAMIENTO ---\n",
    "print(\">>> Preparando datos para reentrenamiento...\")\n",
    "\n",
    "# Importar funci√≥n de preprocesamiento\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos necesarios si no est√°n disponibles\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "    stopwords.words('english')\n",
    "    WordNetLemmatizer().lemmatize(\"test\")\n",
    "except (LookupError, OSError):\n",
    "    print(\"Descargando recursos de NLTK...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "def preprocess_text_advanced(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return ''\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remover patrones m√©dicos espec√≠ficos pero preservar informaci√≥n importante\n",
    "    text = re.sub(r'\\b(patient|enrollee|reviewer|medical|treatment)\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+[-/]\\d+[-/]\\d+\\b', '', text)  # Fechas\n",
    "    text = re.sub(r'\\b\\d{2,4}\\b', '', text)  # A√±os/n√∫meros grandes\n",
    "    \n",
    "    # Preservar t√©rminos m√©dicos importantes\n",
    "    medical_terms = ['hypertension', 'diabetes', 'cardiac', 'hepatitis', 'autism', \n",
    "                    'depression', 'anxiety', 'therapy', 'surgery', 'medication',\n",
    "                    'fever', 'cough', 'fatigue', 'breathing', 'cholesterol']\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatizaci√≥n\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens \n",
    "             if (word not in stop_words and len(word) > 2) or word in medical_terms]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocesar texto\n",
    "df_nuevo['clean_findings'] = df_nuevo['Findings'].apply(preprocess_text_advanced)\n",
    "\n",
    "# Filtrar datos v√°lidos\n",
    "df_nuevo_clean = df_nuevo.dropna(subset=['Diagnosis Category', 'Age Range', 'Patient Gender'])\n",
    "\n",
    "print(f\"Datos limpios: {df_nuevo_clean.shape[0]} filas\")\n",
    "print(f\"Enfermedades √∫nicas en nuevos datos: {df_nuevo_clean['Diagnosis Category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73f5156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ¬øDeseas combinar con datos originales? (recomendado)\n",
      "Datos originales: 19186 filas\n",
      "Dataset combinado: 19535 filas\n",
      "Enfermedades totales √∫nicas: 145\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 5: COMBINAR CON DATOS ORIGINALES (OPCIONAL) ---\n",
    "print(\">>> ¬øDeseas combinar con datos originales? (recomendado)\")\n",
    "\n",
    "# Cargar datos originales\n",
    "try:\n",
    "    df_original = pd.read_csv('datos/Independent_Medical_Reviews.csv')\n",
    "    df_original = df_original.dropna(subset=['Diagnosis Category'])\n",
    "    df_original['clean_findings'] = df_original['Findings'].fillna('').apply(preprocess_text_advanced)\n",
    "    \n",
    "    print(f\"Datos originales: {df_original.shape[0]} filas\")\n",
    "    \n",
    "    # Combinar datasets\n",
    "    df_combinado = pd.concat([\n",
    "        df_original[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']],\n",
    "        df_nuevo_clean[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    print(f\"Dataset combinado: {df_combinado.shape[0]} filas\")\n",
    "    usar_combinado = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"No se pudieron cargar datos originales: {e}\")\n",
    "    print(\"Usando solo nuevos datos...\")\n",
    "    df_combinado = df_nuevo_clean[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']]\n",
    "    usar_combinado = False\n",
    "\n",
    "print(f\"Enfermedades totales √∫nicas: {df_combinado['Diagnosis Category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f58b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Actualizando encoders con nuevas clases...\n",
      "Clases de edad originales: ['0-10', '11_20', '21-30', '31-40', '41-50', '51-64', '65+', 'Unknown']\n",
      "Clases de g√©nero originales: ['Female', 'Male', 'Unknown']\n",
      "Clases de diagn√≥stico originales: 30\n",
      "Nuevas edades encontradas: {'0-20', '71+', nan, '61-70', '51-60'}\n",
      "Nuevos g√©neros encontrados: {nan}\n",
      "Nuevos diagn√≥sticos encontrados: 116 - ['Tetanus', 'Sinusitis', 'Gastroenteritis', 'Conjunctivitis (Pink Eye)', \"Crohn's Disease\"]...\n",
      "Clases finales - Edad: 13, G√©nero: 4, Diagn√≥stico: 146\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 6: ACTUALIZAR ENCODERS CON NUEVAS CLASES ---\n",
    "print(\">>> Actualizando encoders con nuevas clases...\")\n",
    "\n",
    "# Preparar datos\n",
    "X_text = df_combinado['clean_findings']\n",
    "X_cat = df_combinado[['Age Range', 'Patient Gender']]\n",
    "y = df_combinado['Diagnosis Category']\n",
    "\n",
    "# Actualizar encoders para incluir nuevas clases\n",
    "print(\"Clases de edad originales:\", list(age_encoder.classes_))\n",
    "print(\"Clases de g√©nero originales:\", list(gender_encoder.classes_))\n",
    "print(\"Clases de diagn√≥stico originales:\", len(diagnosis_encoder.classes_))\n",
    "\n",
    "# Identificar nuevas clases\n",
    "nuevas_edades = set(X_cat['Age Range'].unique()) - set(age_encoder.classes_)\n",
    "nuevos_generos = set(X_cat['Patient Gender'].unique()) - set(gender_encoder.classes_)\n",
    "nuevos_diagnosticos = set(y.unique()) - set(diagnosis_encoder.classes_)\n",
    "\n",
    "print(f\"Nuevas edades encontradas: {nuevas_edades}\")\n",
    "print(f\"Nuevos g√©neros encontrados: {nuevos_generos}\")\n",
    "print(f\"Nuevos diagn√≥sticos encontrados: {len(nuevos_diagnosticos)} - {list(nuevos_diagnosticos)[:5]}...\")\n",
    "\n",
    "# Crear nuevos encoders que incluyan todas las clases\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Actualizar encoder de edad\n",
    "if nuevas_edades:\n",
    "    todas_edades = list(age_encoder.classes_) + list(nuevas_edades)\n",
    "    age_encoder_nuevo = LabelEncoder()\n",
    "    age_encoder_nuevo.fit(todas_edades)\n",
    "else:\n",
    "    age_encoder_nuevo = age_encoder\n",
    "\n",
    "# Actualizar encoder de g√©nero\n",
    "if nuevos_generos:\n",
    "    todos_generos = list(gender_encoder.classes_) + list(nuevos_generos)\n",
    "    gender_encoder_nuevo = LabelEncoder()\n",
    "    gender_encoder_nuevo.fit(todos_generos)\n",
    "else:\n",
    "    gender_encoder_nuevo = gender_encoder\n",
    "\n",
    "# Actualizar encoder de diagn√≥stico\n",
    "if nuevos_diagnosticos:\n",
    "    todos_diagnosticos = list(diagnosis_encoder.classes_) + list(nuevos_diagnosticos)\n",
    "    diagnosis_encoder_nuevo = LabelEncoder()\n",
    "    diagnosis_encoder_nuevo.fit(todos_diagnosticos)\n",
    "else:\n",
    "    diagnosis_encoder_nuevo = diagnosis_encoder\n",
    "\n",
    "print(f\"Clases finales - Edad: {len(age_encoder_nuevo.classes_)}, G√©nero: {len(gender_encoder_nuevo.classes_)}, Diagn√≥stico: {len(diagnosis_encoder_nuevo.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b162d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reentrenando modelo con nuevos datos...\n",
      "Clases con menos de 2 muestras: 61\n",
      "M√≠nimo de muestras por clase: 1\n",
      "Divisi√≥n aleatoria aplicada (algunas clases tienen muy pocas muestras)\n",
      ">>> Creando mapeo de etiquetas...\n",
      "Etiquetas √∫nicas encontradas: 145\n",
      "Rango de etiquetas originales: 0 a 144\n",
      "Mapeo creado: 145 clases\n",
      ">>> Creando mapeo consecutivo correcto...\n",
      "Etiquetas √∫nicas en entrenamiento: 130\n",
      "Primer mapeo - etiquetas encontradas: [0 1 2 3 4 5 6 7 8 9]...\n",
      "Entrenamiento: 15628 muestras con 130 clases\n",
      "Prueba: 3892 muestras v√°lidas (de 3907 originales)\n",
      "Clases consecutivas: 0 a 129\n",
      "‚úÖ Etiquetas de entrenamiento son perfectamente consecutivas\n",
      ">>> Creando modelo XGBoost...\n",
      ">>> Entrenando modelo...\n",
      "Dimensiones X_train: (15628, 5002)\n",
      "Dimensiones y_train: (15628,)\n",
      "Clases √∫nicas en y_train_consecutive: 130\n",
      "Rango de clases: 0 a 129\n",
      "Iniciando entrenamiento...\n",
      "‚úÖ Entrenamiento completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 7: REENTRENAR MODELO (CORREGIDO) ---\n",
    "print(\">>> Reentrenando modelo con nuevos datos...\")\n",
    "\n",
    "# Preparar caracter√≠sticas\n",
    "X_cat_encoded = pd.DataFrame({\n",
    "    'age_encoded': age_encoder_nuevo.transform(X_cat['Age Range']),\n",
    "    'gender_encoded': gender_encoder_nuevo.transform(X_cat['Patient Gender'])\n",
    "})\n",
    "\n",
    "# Vectorizar texto (actualizar TF-IDF con nuevo vocabulario)\n",
    "tfidf_nuevo = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_nuevo.fit_transform(X_text)\n",
    "\n",
    "# Combinar caracter√≠sticas\n",
    "X_combined = hstack([X_tfidf, X_cat_encoded.values])\n",
    "\n",
    "# Codificar target\n",
    "y_encoded = diagnosis_encoder_nuevo.transform(y)\n",
    "\n",
    "# Verificar clases con pocas muestras\n",
    "from collections import Counter\n",
    "class_counts = Counter(y_encoded)\n",
    "min_samples = min(class_counts.values())\n",
    "classes_with_few_samples = [cls for cls, count in class_counts.items() if count < 2]\n",
    "\n",
    "print(f\"Clases con menos de 2 muestras: {len(classes_with_few_samples)}\")\n",
    "print(f\"M√≠nimo de muestras por clase: {min_samples}\")\n",
    "\n",
    "# FIX 1: Divisi√≥n de datos mejorada\n",
    "try:\n",
    "    if min_samples >= 2:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_combined, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "        )\n",
    "        print(\"Divisi√≥n estratificada aplicada\")\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_combined, y_encoded, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(\"Divisi√≥n aleatoria aplicada (algunas clases tienen muy pocas muestras)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la divisi√≥n de datos: {e}\")\n",
    "    print(\"Aplicando divisi√≥n simple...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_combined, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# FIX 2: Manejo robusto de etiquetas consecutivas\n",
    "print(\">>> Creando mapeo de etiquetas...\")\n",
    "\n",
    "# Obtener todas las etiquetas √∫nicas del conjunto completo\n",
    "unique_labels = np.unique(y_encoded)\n",
    "print(f\"Etiquetas √∫nicas encontradas: {len(unique_labels)}\")\n",
    "print(f\"Rango de etiquetas originales: {min(unique_labels)} a {max(unique_labels)}\")\n",
    "\n",
    "# Crear mapeo bidireccional\n",
    "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
    "reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "\n",
    "print(f\"Mapeo creado: {len(label_mapping)} clases\")\n",
    "\n",
    "# FIX 3: Aplicar mapeo de forma segura (CORREGIDO)\n",
    "print(\">>> Creando mapeo consecutivo correcto...\")\n",
    "\n",
    "try:\n",
    "    # Obtener todas las etiquetas √∫nicas del conjunto de entrenamiento\n",
    "    unique_train_labels = np.unique(y_train)\n",
    "    \n",
    "    print(f\"Etiquetas √∫nicas en entrenamiento: {len(unique_train_labels)}\")\n",
    "    print(f\"Primer mapeo - etiquetas encontradas: {unique_train_labels[:10]}...\")\n",
    "    \n",
    "    # Crear mapeo consecutivo SOLO para las clases presentes en entrenamiento\n",
    "    label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_train_labels)}\n",
    "    reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar mapeo\n",
    "    y_train_consecutive = np.array([label_mapping[label] for label in y_train])\n",
    "    \n",
    "    # Para el conjunto de prueba, mapear solo las etiquetas que existen en entrenamiento\n",
    "    y_test_consecutive = []\n",
    "    valid_test_indices = []\n",
    "    \n",
    "    for i, label in enumerate(y_test):\n",
    "        if label in label_mapping:\n",
    "            y_test_consecutive.append(label_mapping[label])\n",
    "            valid_test_indices.append(i)\n",
    "        # Si la etiqueta no est√° en entrenamiento, la excluimos de la evaluaci√≥n\n",
    "    \n",
    "    y_test_consecutive = np.array(y_test_consecutive)\n",
    "    valid_test_indices = np.array(valid_test_indices)\n",
    "    \n",
    "    # Filtrar X_test para mantener solo las muestras v√°lidas\n",
    "    X_test_filtered = X_test[valid_test_indices]\n",
    "    \n",
    "    print(f\"Entrenamiento: {len(y_train_consecutive)} muestras con {len(np.unique(y_train_consecutive))} clases\")\n",
    "    print(f\"Prueba: {len(y_test_consecutive)} muestras v√°lidas (de {len(y_test)} originales)\")\n",
    "    print(f\"Clases consecutivas: {np.min(y_train_consecutive)} a {np.max(y_train_consecutive)}\")\n",
    "    \n",
    "    # Verificar que ahora S√ç son consecutivas\n",
    "    expected_consecutive = np.arange(len(unique_train_labels))\n",
    "    unique_train_consecutive = np.unique(y_train_consecutive)\n",
    "    \n",
    "    if np.array_equal(unique_train_consecutive, expected_consecutive):\n",
    "        print(\"‚úÖ Etiquetas de entrenamiento son perfectamente consecutivas\")\n",
    "    else:\n",
    "        print(\"‚ùå A√∫n hay problemas con las etiquetas consecutivas\")\n",
    "        print(f\"Esperado: {expected_consecutive}\")\n",
    "        print(f\"Obtenido: {unique_train_consecutive}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error en mapeo de etiquetas: {e}\")\n",
    "    # Fallback m√°s simple\n",
    "    y_train_consecutive = y_train\n",
    "    y_test_consecutive = y_test\n",
    "    X_test_filtered = X_test\n",
    "    label_mapping = {i: i for i in range(len(np.unique(y_train)))}\n",
    "    reverse_mapping = label_mapping.copy()\n",
    "\n",
    "# FIX 4: Crear modelo con par√°metros robustos\n",
    "print(\">>> Creando modelo XGBoost...\")\n",
    "\n",
    "modelo_reentrenado = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    n_estimators=150,  # Reducir a√∫n m√°s\n",
    "    max_depth=5,       # Profundidad m√°s conservadora\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=0        # Reducir verbosidad\n",
    ")\n",
    "\n",
    "# FIX 5: Entrenamiento con verificaci√≥n estricta\n",
    "print(\">>> Entrenando modelo...\")\n",
    "try:\n",
    "    # Verificaciones finales antes del entrenamiento\n",
    "    print(f\"Dimensiones X_train: {X_train.shape}\")\n",
    "    print(f\"Dimensiones y_train: {y_train_consecutive.shape}\")\n",
    "    print(f\"Clases √∫nicas en y_train_consecutive: {len(np.unique(y_train_consecutive))}\")\n",
    "    print(f\"Rango de clases: {np.min(y_train_consecutive)} a {np.max(y_train_consecutive)}\")\n",
    "    \n",
    "    # Verificaci√≥n estricta de consecutividad\n",
    "    unique_classes = np.unique(y_train_consecutive)\n",
    "    expected_classes = np.arange(len(unique_classes))\n",
    "    \n",
    "    if not np.array_equal(unique_classes, expected_classes):\n",
    "        print(\"‚ùå Las clases TODAV√çA no son consecutivas. Corrigiendo...\")\n",
    "        \n",
    "        # Crear un mapeo forzado consecutivo\n",
    "        final_mapping = {old: new for new, old in enumerate(unique_classes)}\n",
    "        y_train_consecutive = np.array([final_mapping[label] for label in y_train_consecutive])\n",
    "        y_test_consecutive = np.array([final_mapping[label] if label in final_mapping else 0 \n",
    "                                     for label in y_test_consecutive])\n",
    "        \n",
    "        # Actualizar mapeos\n",
    "        for old_label, temp_label in label_mapping.items():\n",
    "            if temp_label in final_mapping:\n",
    "                label_mapping[old_label] = final_mapping[temp_label]\n",
    "        \n",
    "        reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "        \n",
    "        print(f\"‚úÖ Clases forzadas a ser consecutivas: 0 a {len(unique_classes)-1}\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    modelo_reentrenado.fit(X_train, y_train_consecutive)\n",
    "    print(\"‚úÖ Entrenamiento completado exitosamente!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error durante el entrenamiento: {e}\")\n",
    "    print(\"Intentando entrenamiento con modelo ultra-simplificado...\")\n",
    "    \n",
    "    # Modelo ultra-simplificado como √∫ltimo recurso\n",
    "    modelo_reentrenado = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        n_estimators=50,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Un solo hilo para evitar problemas\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        modelo_reentrenado.fit(X_train, y_train_consecutive)\n",
    "        print(\"‚úÖ Entrenamiento ultra-simplificado completado!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Error cr√≠tico: {e2}\")\n",
    "        print(\"No se pudo entrenar el modelo. Revisa los datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b2de84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Evaluando modelo...\n",
      "\n",
      ">>> RESULTADOS DEL REENTRENAMIENTO <<<\n",
      "Precisi√≥n del modelo reentrenado: 75.18%\n",
      "Datos de entrenamiento: 15628 muestras\n",
      "Datos de prueba evaluados: 3892 muestras\n",
      "Datos de prueba excluidos: 15 muestras\n",
      "Nuevas clases de diagn√≥stico a√±adidas: 116\n",
      "Total de enfermedades que puede predecir: 146\n",
      "Predicciones √∫nicas generadas: 52\n",
      "\n",
      "Distribuci√≥n de confianza:\n",
      "Confianza promedio: 76.04%\n",
      "Confianza m√≠nima: 6.18%\n",
      "Confianza m√°xima: 99.93%\n",
      "Predicciones con >70% confianza: 2579/3892 (66.3%)\n",
      ">>> Proceso de reentrenamiento finalizado!\n"
     ]
    }
   ],
   "source": [
    "# FIX 6: Evaluaci√≥n con datos filtrados\n",
    "print(\">>> Evaluando modelo...\")\n",
    "try:\n",
    "    if len(y_test_consecutive) > 0:\n",
    "        y_pred = modelo_reentrenado.predict(X_test_filtered)\n",
    "        accuracy = accuracy_score(y_test_consecutive, y_pred)\n",
    "        \n",
    "        print(f\"\\n>>> RESULTADOS DEL REENTRENAMIENTO <<<\")\n",
    "        print(f\"Precisi√≥n del modelo reentrenado: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Datos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "        print(f\"Datos de prueba evaluados: {len(y_test_consecutive)} muestras\")\n",
    "        print(f\"Datos de prueba excluidos: {len(y_test) - len(y_test_consecutive)} muestras\")\n",
    "        print(f\"Nuevas clases de diagn√≥stico a√±adidas: {len(nuevos_diagnosticos)}\")\n",
    "        print(f\"Total de enfermedades que puede predecir: {len(diagnosis_encoder_nuevo.classes_)}\")\n",
    "        \n",
    "        # Verificar predicciones\n",
    "        unique_predictions = np.unique(y_pred)\n",
    "        print(f\"Predicciones √∫nicas generadas: {len(unique_predictions)}\")\n",
    "        \n",
    "        # Mostrar distribuci√≥n de confianza\n",
    "        y_pred_proba = modelo_reentrenado.predict_proba(X_test_filtered)\n",
    "        max_probas = np.max(y_pred_proba, axis=1)\n",
    "        \n",
    "        print(f\"\\nDistribuci√≥n de confianza:\")\n",
    "        print(f\"Confianza promedio: {np.mean(max_probas)*100:.2f}%\")\n",
    "        print(f\"Confianza m√≠nima: {np.min(max_probas)*100:.2f}%\")\n",
    "        print(f\"Confianza m√°xima: {np.max(max_probas)*100:.2f}%\")\n",
    "        \n",
    "        # Predicciones con alta confianza (>70%)\n",
    "        high_confidence = np.sum(max_probas > 0.7)\n",
    "        print(f\"Predicciones con >70% confianza: {high_confidence}/{len(max_probas)} ({high_confidence/len(max_probas)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No hay datos de prueba v√°lidos para evaluar\")\n",
    "        accuracy = 0.0\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error durante la evaluaci√≥n: {e}\")\n",
    "    accuracy = 0.0\n",
    "\n",
    "print(\">>> Proceso de reentrenamiento finalizado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36b4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Guardando modelo reentrenado...\n",
      "‚úÖ Modelo v8 guardado exitosamente!\n",
      "Archivos creados:\n",
      "- modelo_diagnostico_v8_reentrenado.pkl\n",
      "- preprocesadores_v8_reentrenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 8: GUARDAR MODELO REENTRENADO ---\n",
    "print(\">>> Guardando modelo reentrenado...\")\n",
    "\n",
    "try:\n",
    "    # Guardar modelo reentrenado\n",
    "    with open('models/modelo_diagnostico_v8_reentrenado.pkl', 'wb') as f:\n",
    "        pickle.dump(modelo_reentrenado, f)\n",
    "\n",
    "    # Guardar preprocesadores actualizados y mappings\n",
    "    with open('models/preprocesadores_v8_reentrenado.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'tfidf_vectorizer': tfidf_nuevo,\n",
    "            'age_encoder': age_encoder_nuevo,\n",
    "            'gender_encoder': gender_encoder_nuevo,\n",
    "            'diagnosis_encoder': diagnosis_encoder_nuevo,\n",
    "            'label_mapping': label_mapping,\n",
    "            'reverse_mapping': reverse_mapping,\n",
    "            'unique_labels': unique_labels\n",
    "        }, f)\n",
    "\n",
    "    print(\"‚úÖ Modelo v8 guardado exitosamente!\")\n",
    "    print(\"Archivos creados:\")\n",
    "    print(\"- modelo_diagnostico_v8_reentrenado.pkl\")\n",
    "    print(\"- preprocesadores_v8_reentrenado.pkl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error guardando modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a5e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Funci√≥n de predicci√≥n v8 creada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 9: FUNCI√ìN DE PREDICCI√ìN ACTUALIZADA ---\n",
    "def predecir_diagnostico_v8(texto_findings, edad_rango, genero_paciente):\n",
    "    \"\"\"\n",
    "    Funci√≥n de predicci√≥n con modelo v8 reentrenado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocesar texto\n",
    "        texto_limpio = preprocess_text_advanced(texto_findings)\n",
    "        \n",
    "        # Vectorizar\n",
    "        texto_tfidf = tfidf_nuevo.transform([texto_limpio])\n",
    "        \n",
    "        # Validar y codificar categ√≥ricas\n",
    "        if edad_rango not in age_encoder_nuevo.classes_:\n",
    "            print(f\"Advertencia: Edad '{edad_rango}' no reconocida. Usando '31-40'.\")\n",
    "            edad_rango = \"31-40\"  # Valor por defecto com√∫n\n",
    "            \n",
    "        if genero_paciente not in gender_encoder_nuevo.classes_:\n",
    "            print(f\"Advertencia: G√©nero '{genero_paciente}' no reconocido. Usando 'Male'.\")\n",
    "            genero_paciente = \"Male\"  # Valor por defecto\n",
    "            \n",
    "        edad_encoded = age_encoder_nuevo.transform([edad_rango])\n",
    "        genero_encoded = gender_encoder_nuevo.transform([genero_paciente])\n",
    "        \n",
    "        # Combinar caracter√≠sticas\n",
    "        caracteristicas_categoricas = np.array([[edad_encoded[0], genero_encoded[0]]])\n",
    "        caracteristicas_combinadas = hstack([texto_tfidf, caracteristicas_categoricas])\n",
    "        \n",
    "        # Predicci√≥n con etiquetas consecutivas\n",
    "        prediccion_consecutiva = modelo_reentrenado.predict(caracteristicas_combinadas)\n",
    "        probabilidades = modelo_reentrenado.predict_proba(caracteristicas_combinadas)\n",
    "        \n",
    "        # Convertir de etiquetas consecutivas a originales\n",
    "        prediccion_original = reverse_mapping[prediccion_consecutiva[0]]\n",
    "        \n",
    "        # Decodificar a nombre de enfermedad\n",
    "        categoria_predicha = diagnosis_encoder_nuevo.inverse_transform([prediccion_original])[0]\n",
    "        confianza = max(probabilidades[0]) * 100\n",
    "        \n",
    "        # Top 5 predicciones\n",
    "        top_indices = np.argsort(probabilidades[0])[::-1][:5]\n",
    "        top_categorias = []\n",
    "        for i in top_indices:\n",
    "            # Convertir √≠ndice consecutivo a etiqueta original\n",
    "            etiqueta_original = reverse_mapping[i]\n",
    "            categoria = diagnosis_encoder_nuevo.inverse_transform([etiqueta_original])[0]\n",
    "            prob = probabilidades[0][i] * 100\n",
    "            top_categorias.append({\n",
    "                \"disease\": categoria,\n",
    "                \"probability\": round(prob, 2)\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            'success': True,\n",
    "            'main_diagnosis': categoria_predicha,\n",
    "            'confidence': round(confianza, 2),\n",
    "            'top_predictions': top_categorias,\n",
    "            'processed_text': texto_limpio,\n",
    "            'model_version': 'v8_reentrenado'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'model_version': 'v8_reentrenado'\n",
    "        }\n",
    "\n",
    "print(\">>> Funci√≥n de predicci√≥n v8 creada exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "662e11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Probando modelo v8 reentrenado...\n",
      "\n",
      "=== PRUEBAS DEL MODELO v8 ===\n",
      "\n",
      "--- CASO 1: Asma ---\n",
      "Predicci√≥n: Orthopedic/ Musculoskeletal\n",
      "Confianza: 17.809999465942383%\n",
      "Top 3 predicciones:\n",
      "  1. Orthopedic/ Musculoskeletal: 17.809999465942383%\n",
      "  2. Central Nervous System/ Neuromuscular: 17.760000228881836%\n",
      "  3. Mental: 9.520000457763672%\n",
      "‚ùå Predicci√≥n incorrecta\n",
      "\n",
      "--- CASO 2: Diabetes ---\n",
      "Predicci√≥n: Central Nervous System/ Neuromuscular\n",
      "Confianza: 19.3700008392334%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 19.3700008392334%\n",
      "  2. Orthopedic/ Musculoskeletal: 15.5600004196167%\n",
      "  3. Cancer: 8.210000038146973%\n",
      "‚ùå Predicci√≥n incorrecta\n",
      "\n",
      "--- CASO 3: Influenza ---\n",
      "Predicci√≥n: Central Nervous System/ Neuromuscular\n",
      "Confianza: 15.270000457763672%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 15.270000457763672%\n",
      "  2. Orthopedic/ Musculoskeletal: 14.529999732971191%\n",
      "  3. Mental: 8.180000305175781%\n",
      "‚ùå Predicci√≥n incorrecta\n",
      "\n",
      "--- CASO 4: Migra√±a ---\n",
      "Predicci√≥n: Central Nervous System/ Neuromuscular\n",
      "Confianza: 83.79000091552734%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 83.79000091552734%\n",
      "  2. Skin: 4.380000114440918%\n",
      "  3. Digestive System/ Gastrointestinal: 3.809999942779541%\n",
      "‚ùå Predicci√≥n incorrecta\n",
      "\n",
      "--- CASO 5: Eczema ---\n",
      "Predicci√≥n: Skin\n",
      "Confianza: 39.16999816894531%\n",
      "Top 3 predicciones:\n",
      "  1. Skin: 39.16999816894531%\n",
      "  2. Central Nervous System/ Neuromuscular: 10.199999809265137%\n",
      "  3. Orthopedic/ Musculoskeletal: 9.350000381469727%\n",
      "‚ùå Predicci√≥n incorrecta\n",
      "\n",
      "üìä RESUMEN DE PRUEBAS:\n",
      "Casos correctos: 0/5\n",
      "Precisi√≥n en casos de prueba: 0.0%\n",
      "\n",
      ">>> ¬°Modelo v8 reentrenado completado!\n",
      "üìä Precisi√≥n general: 75.18%\n",
      "üéØ Precisi√≥n en pruebas espec√≠ficas: 0.0%\n",
      "üè• Total enfermedades: 146\n",
      "üÜï Nuevas enfermedades a√±adidas: 116\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 10: PRUEBAS DEL MODELO REENTRENADO ---\n",
    "print(\"\\n>>> Probando modelo v8 reentrenado...\")\n",
    "\n",
    "# Casos de prueba espec√≠ficos del nuevo dataset\n",
    "casos_prueba_v8 = [\n",
    "    {\n",
    "        \"nombre\": \"Asma\",\n",
    "        \"symptoms\": \"Patient presents with cough, difficulty breathing, wheezing\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Male\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Diabetes\", \n",
    "        \"symptoms\": \"Patient reports fatigue, excessive thirst, frequent urination\",\n",
    "        \"age_range\": \"41-50\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Influenza\",\n",
    "        \"symptoms\": \"Patient presents with fever, cough, body aches, fatigue\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Migra√±a\",\n",
    "        \"symptoms\": \"Patient reports severe headache, sensitivity to light, nausea\",\n",
    "        \"age_range\": \"31-40\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Eczema\",\n",
    "        \"symptoms\": \"Patient has skin rash, itching, dry skin patches\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Female\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n=== PRUEBAS DEL MODELO v8 ===\")\n",
    "aciertos = 0\n",
    "total_casos = len(casos_prueba_v8)\n",
    "\n",
    "for i, caso in enumerate(casos_prueba_v8, 1):\n",
    "    print(f\"\\n--- CASO {i}: {caso['nombre']} ---\")\n",
    "    \n",
    "    resultado = predecir_diagnostico_v8(\n",
    "        caso['symptoms'],\n",
    "        caso['age_range'], \n",
    "        caso['gender']\n",
    "    )\n",
    "    \n",
    "    if resultado['success']:\n",
    "        print(f\"Predicci√≥n: {resultado['main_diagnosis']}\")\n",
    "        print(f\"Confianza: {resultado['confidence']}%\")\n",
    "        print(\"Top 3 predicciones:\")\n",
    "        for j, pred in enumerate(resultado['top_predictions'][:3], 1):\n",
    "            print(f\"  {j}. {pred['disease']}: {pred['probability']}%\")\n",
    "        \n",
    "        # Verificar si la predicci√≥n es correcta\n",
    "        esperado = caso['nombre'].lower()\n",
    "        prediccion = resultado['main_diagnosis'].lower()\n",
    "        \n",
    "        # Buscar en predicci√≥n principal y top 3\n",
    "        encontrado = (esperado in prediccion or \n",
    "                     any(esperado in pred['disease'].lower() \n",
    "                         for pred in resultado['top_predictions'][:3]))\n",
    "        \n",
    "        if encontrado:\n",
    "            print(\"‚úÖ Predicci√≥n CORRECTA\")\n",
    "            aciertos += 1\n",
    "        else:\n",
    "            print(\"‚ùå Predicci√≥n incorrecta\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {resultado['error']}\")\n",
    "\n",
    "# Calcular precisi√≥n en casos de prueba\n",
    "precision_casos = (aciertos / total_casos) * 100\n",
    "print(f\"\\nüìä RESUMEN DE PRUEBAS:\")\n",
    "print(f\"Casos correctos: {aciertos}/{total_casos}\")\n",
    "print(f\"Precisi√≥n en casos de prueba: {precision_casos:.1f}%\")\n",
    "\n",
    "print(f\"\\n>>> ¬°Modelo v8 reentrenado completado!\")\n",
    "print(f\"üìä Precisi√≥n general: {accuracy*100:.2f}%\")\n",
    "print(f\"üéØ Precisi√≥n en pruebas espec√≠ficas: {precision_casos:.1f}%\")\n",
    "print(f\"üè• Total enfermedades: {len(diagnosis_encoder_nuevo.classes_)}\")\n",
    "print(f\"üÜï Nuevas enfermedades a√±adidas: {len(nuevos_diagnosticos)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
