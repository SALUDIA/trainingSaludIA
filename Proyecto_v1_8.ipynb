{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd42a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando modelo y preprocesadores existentes...\n",
      ">>> Modelo y preprocesadores cargados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 1: CARGAR MODELO Y PREPROCESADORES EXISTENTES ---\n",
    "print(\">>> Cargando modelo y preprocesadores existentes...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cargar modelo entrenado\n",
    "with open('models\\modelo_diagnostico_v6_xgboost.pkl', 'rb') as f:\n",
    "    modelo_existente = pickle.load(f)\n",
    "\n",
    "# Cargar preprocesadores\n",
    "with open('models\\preprocesadores_v6.pkl', 'rb') as f:\n",
    "    preprocesadores = pickle.load(f)\n",
    "    tfidf_vectorizer = preprocesadores['tfidf_vectorizer']\n",
    "    age_encoder = preprocesadores['age_encoder']\n",
    "    gender_encoder = preprocesadores['gender_encoder']\n",
    "    diagnosis_encoder = preprocesadores['diagnosis_encoder']\n",
    "\n",
    "print(\">>> Modelo y preprocesadores cargados exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02c1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando nuevo dataset...\n",
      "Nuevo dataset cargado: 349 filas, 10 columnas\n",
      "\n",
      "Primeras filas del nuevo dataset:\n",
      "       Disease Fever Cough Fatigue Difficulty Breathing  Age  Gender  \\\n",
      "0    Influenza   Yes    No     Yes                  Yes   19  Female   \n",
      "1  Common Cold    No   Yes     Yes                   No   25  Female   \n",
      "2       Eczema    No   Yes     Yes                   No   25  Female   \n",
      "3       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "4       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "\n",
      "  Blood Pressure Cholesterol Level Outcome Variable  \n",
      "0            Low            Normal         Positive  \n",
      "1         Normal            Normal         Negative  \n",
      "2         Normal            Normal         Negative  \n",
      "3         Normal            Normal         Positive  \n",
      "4         Normal            Normal         Positive  \n",
      "\n",
      "Columnas disponibles: ['Disease', 'Fever', 'Cough', 'Fatigue', 'Difficulty Breathing', 'Age', 'Gender', 'Blood Pressure', 'Cholesterol Level', 'Outcome Variable']\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 2: CARGAR Y PREPARAR NUEVOS DATOS ---\n",
    "print(\">>> Cargando nuevo dataset...\")\n",
    "\n",
    "# Cargar el nuevo dataset\n",
    "df_nuevo = pd.read_csv('datos/Disease_symptom_and_patient_profile_dataset.csv')\n",
    "print(f\"Nuevo dataset cargado: {df_nuevo.shape[0]} filas, {df_nuevo.shape[1]} columnas\")\n",
    "\n",
    "# Mostrar primeras filas para entender la estructura\n",
    "print(\"\\nPrimeras filas del nuevo dataset:\")\n",
    "print(df_nuevo.head())\n",
    "\n",
    "# Mostrar columnas disponibles\n",
    "print(f\"\\nColumnas disponibles: {list(df_nuevo.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06381880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Transformando nuevos datos al formato compatible...\n",
      ">>> Datos transformados exitosamente!\n",
      "Ejemplo de texto generado:\n",
      "Patient presents with fever, fatigue, difficulty breathing, hypotension. Age: 19 years old, Gender: Female, Blood pressure: Low, Cholesterol: Normal.\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 3: TRANSFORMAR NUEVOS DATOS AL FORMATO DEL MODELO ORIGINAL ---\n",
    "print(\">>> Transformando nuevos datos al formato compatible...\")\n",
    "\n",
    "# Crear texto de \"findings\" basado en los síntomas\n",
    "def crear_findings_texto(row):\n",
    "    symptoms = []\n",
    "    if row['Fever'] == 'Yes':\n",
    "        symptoms.append('fever')\n",
    "    if row['Cough'] == 'Yes':\n",
    "        symptoms.append('cough')\n",
    "    if row['Fatigue'] == 'Yes':\n",
    "        symptoms.append('fatigue')\n",
    "    if row['Difficulty Breathing'] == 'Yes':\n",
    "        symptoms.append('difficulty breathing')\n",
    "    \n",
    "    # Agregar información adicional\n",
    "    if row['Blood Pressure'] == 'High':\n",
    "        symptoms.append('hypertension')\n",
    "    elif row['Blood Pressure'] == 'Low':\n",
    "        symptoms.append('hypotension')\n",
    "        \n",
    "    if row['Cholesterol Level'] == 'High':\n",
    "        symptoms.append('high cholesterol')\n",
    "    elif row['Cholesterol Level'] == 'Low':\n",
    "        symptoms.append('low cholesterol')\n",
    "    \n",
    "    # Crear texto descriptivo\n",
    "    findings_text = f\"Patient presents with {', '.join(symptoms)}. \"\n",
    "    findings_text += f\"Age: {row['Age']} years old, Gender: {row['Gender']}, \"\n",
    "    findings_text += f\"Blood pressure: {row['Blood Pressure']}, Cholesterol: {row['Cholesterol Level']}.\"\n",
    "    \n",
    "    return findings_text\n",
    "\n",
    "# Aplicar transformación\n",
    "df_nuevo['Findings'] = df_nuevo.apply(crear_findings_texto, axis=1)\n",
    "\n",
    "# Mapear rangos de edad (adaptar al formato original)\n",
    "def mapear_edad(edad):\n",
    "    if edad <= 20:\n",
    "        return \"0-20\"\n",
    "    elif edad <= 30:\n",
    "        return \"21-30\"\n",
    "    elif edad <= 40:\n",
    "        return \"31-40\"\n",
    "    elif edad <= 50:\n",
    "        return \"41-50\"\n",
    "    elif edad <= 60:\n",
    "        return \"51-60\"\n",
    "    elif edad <= 70:\n",
    "        return \"61-70\"\n",
    "    else:\n",
    "        return \"71+\"\n",
    "\n",
    "df_nuevo['Age Range'] = df_nuevo['Age'].apply(mapear_edad)\n",
    "df_nuevo['Patient Gender'] = df_nuevo['Gender']\n",
    "df_nuevo['Diagnosis Category'] = df_nuevo['Disease']\n",
    "\n",
    "print(\">>> Datos transformados exitosamente!\")\n",
    "print(f\"Ejemplo de texto generado:\")\n",
    "print(df_nuevo['Findings'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15144888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Preparando datos para reentrenamiento...\n",
      "Datos limpios: 349 filas\n",
      "Enfermedades únicas en nuevos datos: 116\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 4: PREPARAR DATOS PARA REENTRENAMIENTO ---\n",
    "print(\">>> Preparando datos para reentrenamiento...\")\n",
    "\n",
    "# Importar función de preprocesamiento\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos necesarios si no están disponibles\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "    stopwords.words('english')\n",
    "    WordNetLemmatizer().lemmatize(\"test\")\n",
    "except (LookupError, OSError):\n",
    "    print(\"Descargando recursos de NLTK...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "def preprocess_text_advanced(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return ''\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remover patrones médicos específicos pero preservar información importante\n",
    "    text = re.sub(r'\\b(patient|enrollee|reviewer|medical|treatment)\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+[-/]\\d+[-/]\\d+\\b', '', text)  # Fechas\n",
    "    text = re.sub(r'\\b\\d{2,4}\\b', '', text)  # Años/números grandes\n",
    "    \n",
    "    # Preservar términos médicos importantes\n",
    "    medical_terms = ['hypertension', 'diabetes', 'cardiac', 'hepatitis', 'autism', \n",
    "                    'depression', 'anxiety', 'therapy', 'surgery', 'medication',\n",
    "                    'fever', 'cough', 'fatigue', 'breathing', 'cholesterol']\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens \n",
    "             if (word not in stop_words and len(word) > 2) or word in medical_terms]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocesar texto\n",
    "df_nuevo['clean_findings'] = df_nuevo['Findings'].apply(preprocess_text_advanced)\n",
    "\n",
    "# Filtrar datos válidos\n",
    "df_nuevo_clean = df_nuevo.dropna(subset=['Diagnosis Category', 'Age Range', 'Patient Gender'])\n",
    "\n",
    "print(f\"Datos limpios: {df_nuevo_clean.shape[0]} filas\")\n",
    "print(f\"Enfermedades únicas en nuevos datos: {df_nuevo_clean['Diagnosis Category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73f5156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ¿Deseas combinar con datos originales? (recomendado)\n",
      "Datos originales: 19186 filas\n",
      "Dataset combinado: 19535 filas\n",
      "Enfermedades totales únicas: 145\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 5: COMBINAR CON DATOS ORIGINALES (OPCIONAL) ---\n",
    "print(\">>> ¿Deseas combinar con datos originales? (recomendado)\")\n",
    "\n",
    "# Cargar datos originales\n",
    "try:\n",
    "    df_original = pd.read_csv('datos/Independent_Medical_Reviews.csv')\n",
    "    df_original = df_original.dropna(subset=['Diagnosis Category'])\n",
    "    df_original['clean_findings'] = df_original['Findings'].fillna('').apply(preprocess_text_advanced)\n",
    "    \n",
    "    print(f\"Datos originales: {df_original.shape[0]} filas\")\n",
    "    \n",
    "    # Combinar datasets\n",
    "    df_combinado = pd.concat([\n",
    "        df_original[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']],\n",
    "        df_nuevo_clean[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    print(f\"Dataset combinado: {df_combinado.shape[0]} filas\")\n",
    "    usar_combinado = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"No se pudieron cargar datos originales: {e}\")\n",
    "    print(\"Usando solo nuevos datos...\")\n",
    "    df_combinado = df_nuevo_clean[['clean_findings', 'Age Range', 'Patient Gender', 'Diagnosis Category']]\n",
    "    usar_combinado = False\n",
    "\n",
    "print(f\"Enfermedades totales únicas: {df_combinado['Diagnosis Category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f58b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Actualizando encoders con nuevas clases...\n",
      "Clases de edad originales: ['0-10', '11_20', '21-30', '31-40', '41-50', '51-64', '65+', 'Unknown']\n",
      "Clases de género originales: ['Female', 'Male', 'Unknown']\n",
      "Clases de diagnóstico originales: 30\n",
      "Nuevas edades encontradas: {'0-20', '71+', nan, '61-70', '51-60'}\n",
      "Nuevos géneros encontrados: {nan}\n",
      "Nuevos diagnósticos encontrados: 116 - ['Tetanus', 'Sinusitis', 'Gastroenteritis', 'Conjunctivitis (Pink Eye)', \"Crohn's Disease\"]...\n",
      "Clases finales - Edad: 13, Género: 4, Diagnóstico: 146\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 6: ACTUALIZAR ENCODERS CON NUEVAS CLASES ---\n",
    "print(\">>> Actualizando encoders con nuevas clases...\")\n",
    "\n",
    "# Preparar datos\n",
    "X_text = df_combinado['clean_findings']\n",
    "X_cat = df_combinado[['Age Range', 'Patient Gender']]\n",
    "y = df_combinado['Diagnosis Category']\n",
    "\n",
    "# Actualizar encoders para incluir nuevas clases\n",
    "print(\"Clases de edad originales:\", list(age_encoder.classes_))\n",
    "print(\"Clases de género originales:\", list(gender_encoder.classes_))\n",
    "print(\"Clases de diagnóstico originales:\", len(diagnosis_encoder.classes_))\n",
    "\n",
    "# Identificar nuevas clases\n",
    "nuevas_edades = set(X_cat['Age Range'].unique()) - set(age_encoder.classes_)\n",
    "nuevos_generos = set(X_cat['Patient Gender'].unique()) - set(gender_encoder.classes_)\n",
    "nuevos_diagnosticos = set(y.unique()) - set(diagnosis_encoder.classes_)\n",
    "\n",
    "print(f\"Nuevas edades encontradas: {nuevas_edades}\")\n",
    "print(f\"Nuevos géneros encontrados: {nuevos_generos}\")\n",
    "print(f\"Nuevos diagnósticos encontrados: {len(nuevos_diagnosticos)} - {list(nuevos_diagnosticos)[:5]}...\")\n",
    "\n",
    "# Crear nuevos encoders que incluyan todas las clases\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Actualizar encoder de edad\n",
    "if nuevas_edades:\n",
    "    todas_edades = list(age_encoder.classes_) + list(nuevas_edades)\n",
    "    age_encoder_nuevo = LabelEncoder()\n",
    "    age_encoder_nuevo.fit(todas_edades)\n",
    "else:\n",
    "    age_encoder_nuevo = age_encoder\n",
    "\n",
    "# Actualizar encoder de género\n",
    "if nuevos_generos:\n",
    "    todos_generos = list(gender_encoder.classes_) + list(nuevos_generos)\n",
    "    gender_encoder_nuevo = LabelEncoder()\n",
    "    gender_encoder_nuevo.fit(todos_generos)\n",
    "else:\n",
    "    gender_encoder_nuevo = gender_encoder\n",
    "\n",
    "# Actualizar encoder de diagnóstico\n",
    "if nuevos_diagnosticos:\n",
    "    todos_diagnosticos = list(diagnosis_encoder.classes_) + list(nuevos_diagnosticos)\n",
    "    diagnosis_encoder_nuevo = LabelEncoder()\n",
    "    diagnosis_encoder_nuevo.fit(todos_diagnosticos)\n",
    "else:\n",
    "    diagnosis_encoder_nuevo = diagnosis_encoder\n",
    "\n",
    "print(f\"Clases finales - Edad: {len(age_encoder_nuevo.classes_)}, Género: {len(gender_encoder_nuevo.classes_)}, Diagnóstico: {len(diagnosis_encoder_nuevo.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b162d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reentrenando modelo con nuevos datos...\n",
      "Clases con menos de 2 muestras: 61\n",
      "Mínimo de muestras por clase: 1\n",
      "División aleatoria aplicada (algunas clases tienen muy pocas muestras)\n",
      ">>> Creando mapeo de etiquetas...\n",
      "Etiquetas únicas encontradas: 145\n",
      "Rango de etiquetas originales: 0 a 144\n",
      "Mapeo creado: 145 clases\n",
      ">>> Creando mapeo consecutivo correcto...\n",
      "Etiquetas únicas en entrenamiento: 130\n",
      "Primer mapeo - etiquetas encontradas: [0 1 2 3 4 5 6 7 8 9]...\n",
      "Entrenamiento: 15628 muestras con 130 clases\n",
      "Prueba: 3892 muestras válidas (de 3907 originales)\n",
      "Clases consecutivas: 0 a 129\n",
      "✅ Etiquetas de entrenamiento son perfectamente consecutivas\n",
      ">>> Creando modelo XGBoost...\n",
      ">>> Entrenando modelo...\n",
      "Dimensiones X_train: (15628, 5002)\n",
      "Dimensiones y_train: (15628,)\n",
      "Clases únicas en y_train_consecutive: 130\n",
      "Rango de clases: 0 a 129\n",
      "Iniciando entrenamiento...\n",
      "✅ Entrenamiento completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 7: REENTRENAR MODELO (CORREGIDO) ---\n",
    "print(\">>> Reentrenando modelo con nuevos datos...\")\n",
    "\n",
    "# Preparar características\n",
    "X_cat_encoded = pd.DataFrame({\n",
    "    'age_encoded': age_encoder_nuevo.transform(X_cat['Age Range']),\n",
    "    'gender_encoded': gender_encoder_nuevo.transform(X_cat['Patient Gender'])\n",
    "})\n",
    "\n",
    "# Vectorizar texto (actualizar TF-IDF con nuevo vocabulario)\n",
    "tfidf_nuevo = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_nuevo.fit_transform(X_text)\n",
    "\n",
    "# Combinar características\n",
    "X_combined = hstack([X_tfidf, X_cat_encoded.values])\n",
    "\n",
    "# Codificar target\n",
    "y_encoded = diagnosis_encoder_nuevo.transform(y)\n",
    "\n",
    "# Verificar clases con pocas muestras\n",
    "from collections import Counter\n",
    "class_counts = Counter(y_encoded)\n",
    "min_samples = min(class_counts.values())\n",
    "classes_with_few_samples = [cls for cls, count in class_counts.items() if count < 2]\n",
    "\n",
    "print(f\"Clases con menos de 2 muestras: {len(classes_with_few_samples)}\")\n",
    "print(f\"Mínimo de muestras por clase: {min_samples}\")\n",
    "\n",
    "# FIX 1: División de datos mejorada\n",
    "try:\n",
    "    if min_samples >= 2:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_combined, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "        )\n",
    "        print(\"División estratificada aplicada\")\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_combined, y_encoded, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(\"División aleatoria aplicada (algunas clases tienen muy pocas muestras)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la división de datos: {e}\")\n",
    "    print(\"Aplicando división simple...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_combined, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# FIX 2: Manejo robusto de etiquetas consecutivas\n",
    "print(\">>> Creando mapeo de etiquetas...\")\n",
    "\n",
    "# Obtener todas las etiquetas únicas del conjunto completo\n",
    "unique_labels = np.unique(y_encoded)\n",
    "print(f\"Etiquetas únicas encontradas: {len(unique_labels)}\")\n",
    "print(f\"Rango de etiquetas originales: {min(unique_labels)} a {max(unique_labels)}\")\n",
    "\n",
    "# Crear mapeo bidireccional\n",
    "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
    "reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "\n",
    "print(f\"Mapeo creado: {len(label_mapping)} clases\")\n",
    "\n",
    "# FIX 3: Aplicar mapeo de forma segura (CORREGIDO)\n",
    "print(\">>> Creando mapeo consecutivo correcto...\")\n",
    "\n",
    "try:\n",
    "    # Obtener todas las etiquetas únicas del conjunto de entrenamiento\n",
    "    unique_train_labels = np.unique(y_train)\n",
    "    \n",
    "    print(f\"Etiquetas únicas en entrenamiento: {len(unique_train_labels)}\")\n",
    "    print(f\"Primer mapeo - etiquetas encontradas: {unique_train_labels[:10]}...\")\n",
    "    \n",
    "    # Crear mapeo consecutivo SOLO para las clases presentes en entrenamiento\n",
    "    label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_train_labels)}\n",
    "    reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar mapeo\n",
    "    y_train_consecutive = np.array([label_mapping[label] for label in y_train])\n",
    "    \n",
    "    # Para el conjunto de prueba, mapear solo las etiquetas que existen en entrenamiento\n",
    "    y_test_consecutive = []\n",
    "    valid_test_indices = []\n",
    "    \n",
    "    for i, label in enumerate(y_test):\n",
    "        if label in label_mapping:\n",
    "            y_test_consecutive.append(label_mapping[label])\n",
    "            valid_test_indices.append(i)\n",
    "        # Si la etiqueta no está en entrenamiento, la excluimos de la evaluación\n",
    "    \n",
    "    y_test_consecutive = np.array(y_test_consecutive)\n",
    "    valid_test_indices = np.array(valid_test_indices)\n",
    "    \n",
    "    # Filtrar X_test para mantener solo las muestras válidas\n",
    "    X_test_filtered = X_test[valid_test_indices]\n",
    "    \n",
    "    print(f\"Entrenamiento: {len(y_train_consecutive)} muestras con {len(np.unique(y_train_consecutive))} clases\")\n",
    "    print(f\"Prueba: {len(y_test_consecutive)} muestras válidas (de {len(y_test)} originales)\")\n",
    "    print(f\"Clases consecutivas: {np.min(y_train_consecutive)} a {np.max(y_train_consecutive)}\")\n",
    "    \n",
    "    # Verificar que ahora SÍ son consecutivas\n",
    "    expected_consecutive = np.arange(len(unique_train_labels))\n",
    "    unique_train_consecutive = np.unique(y_train_consecutive)\n",
    "    \n",
    "    if np.array_equal(unique_train_consecutive, expected_consecutive):\n",
    "        print(\"✅ Etiquetas de entrenamiento son perfectamente consecutivas\")\n",
    "    else:\n",
    "        print(\"❌ Aún hay problemas con las etiquetas consecutivas\")\n",
    "        print(f\"Esperado: {expected_consecutive}\")\n",
    "        print(f\"Obtenido: {unique_train_consecutive}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error en mapeo de etiquetas: {e}\")\n",
    "    # Fallback más simple\n",
    "    y_train_consecutive = y_train\n",
    "    y_test_consecutive = y_test\n",
    "    X_test_filtered = X_test\n",
    "    label_mapping = {i: i for i in range(len(np.unique(y_train)))}\n",
    "    reverse_mapping = label_mapping.copy()\n",
    "\n",
    "# FIX 4: Crear modelo con parámetros robustos\n",
    "print(\">>> Creando modelo XGBoost...\")\n",
    "\n",
    "modelo_reentrenado = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    n_estimators=150,  # Reducir aún más\n",
    "    max_depth=5,       # Profundidad más conservadora\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=0        # Reducir verbosidad\n",
    ")\n",
    "\n",
    "# FIX 5: Entrenamiento con verificación estricta\n",
    "print(\">>> Entrenando modelo...\")\n",
    "try:\n",
    "    # Verificaciones finales antes del entrenamiento\n",
    "    print(f\"Dimensiones X_train: {X_train.shape}\")\n",
    "    print(f\"Dimensiones y_train: {y_train_consecutive.shape}\")\n",
    "    print(f\"Clases únicas en y_train_consecutive: {len(np.unique(y_train_consecutive))}\")\n",
    "    print(f\"Rango de clases: {np.min(y_train_consecutive)} a {np.max(y_train_consecutive)}\")\n",
    "    \n",
    "    # Verificación estricta de consecutividad\n",
    "    unique_classes = np.unique(y_train_consecutive)\n",
    "    expected_classes = np.arange(len(unique_classes))\n",
    "    \n",
    "    if not np.array_equal(unique_classes, expected_classes):\n",
    "        print(\"❌ Las clases TODAVÍA no son consecutivas. Corrigiendo...\")\n",
    "        \n",
    "        # Crear un mapeo forzado consecutivo\n",
    "        final_mapping = {old: new for new, old in enumerate(unique_classes)}\n",
    "        y_train_consecutive = np.array([final_mapping[label] for label in y_train_consecutive])\n",
    "        y_test_consecutive = np.array([final_mapping[label] if label in final_mapping else 0 \n",
    "                                     for label in y_test_consecutive])\n",
    "        \n",
    "        # Actualizar mapeos\n",
    "        for old_label, temp_label in label_mapping.items():\n",
    "            if temp_label in final_mapping:\n",
    "                label_mapping[old_label] = final_mapping[temp_label]\n",
    "        \n",
    "        reverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "        \n",
    "        print(f\"✅ Clases forzadas a ser consecutivas: 0 a {len(unique_classes)-1}\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    modelo_reentrenado.fit(X_train, y_train_consecutive)\n",
    "    print(\"✅ Entrenamiento completado exitosamente!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante el entrenamiento: {e}\")\n",
    "    print(\"Intentando entrenamiento con modelo ultra-simplificado...\")\n",
    "    \n",
    "    # Modelo ultra-simplificado como último recurso\n",
    "    modelo_reentrenado = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        n_estimators=50,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Un solo hilo para evitar problemas\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        modelo_reentrenado.fit(X_train, y_train_consecutive)\n",
    "        print(\"✅ Entrenamiento ultra-simplificado completado!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Error crítico: {e2}\")\n",
    "        print(\"No se pudo entrenar el modelo. Revisa los datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b2de84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Evaluando modelo...\n",
      "\n",
      ">>> RESULTADOS DEL REENTRENAMIENTO <<<\n",
      "Precisión del modelo reentrenado: 75.18%\n",
      "Datos de entrenamiento: 15628 muestras\n",
      "Datos de prueba evaluados: 3892 muestras\n",
      "Datos de prueba excluidos: 15 muestras\n",
      "Nuevas clases de diagnóstico añadidas: 116\n",
      "Total de enfermedades que puede predecir: 146\n",
      "Predicciones únicas generadas: 52\n",
      "\n",
      "Distribución de confianza:\n",
      "Confianza promedio: 76.04%\n",
      "Confianza mínima: 6.18%\n",
      "Confianza máxima: 99.93%\n",
      "Predicciones con >70% confianza: 2579/3892 (66.3%)\n",
      ">>> Proceso de reentrenamiento finalizado!\n"
     ]
    }
   ],
   "source": [
    "# FIX 6: Evaluación con datos filtrados\n",
    "print(\">>> Evaluando modelo...\")\n",
    "try:\n",
    "    if len(y_test_consecutive) > 0:\n",
    "        y_pred = modelo_reentrenado.predict(X_test_filtered)\n",
    "        accuracy = accuracy_score(y_test_consecutive, y_pred)\n",
    "        \n",
    "        print(f\"\\n>>> RESULTADOS DEL REENTRENAMIENTO <<<\")\n",
    "        print(f\"Precisión del modelo reentrenado: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Datos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "        print(f\"Datos de prueba evaluados: {len(y_test_consecutive)} muestras\")\n",
    "        print(f\"Datos de prueba excluidos: {len(y_test) - len(y_test_consecutive)} muestras\")\n",
    "        print(f\"Nuevas clases de diagnóstico añadidas: {len(nuevos_diagnosticos)}\")\n",
    "        print(f\"Total de enfermedades que puede predecir: {len(diagnosis_encoder_nuevo.classes_)}\")\n",
    "        \n",
    "        # Verificar predicciones\n",
    "        unique_predictions = np.unique(y_pred)\n",
    "        print(f\"Predicciones únicas generadas: {len(unique_predictions)}\")\n",
    "        \n",
    "        # Mostrar distribución de confianza\n",
    "        y_pred_proba = modelo_reentrenado.predict_proba(X_test_filtered)\n",
    "        max_probas = np.max(y_pred_proba, axis=1)\n",
    "        \n",
    "        print(f\"\\nDistribución de confianza:\")\n",
    "        print(f\"Confianza promedio: {np.mean(max_probas)*100:.2f}%\")\n",
    "        print(f\"Confianza mínima: {np.min(max_probas)*100:.2f}%\")\n",
    "        print(f\"Confianza máxima: {np.max(max_probas)*100:.2f}%\")\n",
    "        \n",
    "        # Predicciones con alta confianza (>70%)\n",
    "        high_confidence = np.sum(max_probas > 0.7)\n",
    "        print(f\"Predicciones con >70% confianza: {high_confidence}/{len(max_probas)} ({high_confidence/len(max_probas)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No hay datos de prueba válidos para evaluar\")\n",
    "        accuracy = 0.0\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante la evaluación: {e}\")\n",
    "    accuracy = 0.0\n",
    "\n",
    "print(\">>> Proceso de reentrenamiento finalizado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36b4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Guardando modelo reentrenado...\n",
      "✅ Modelo v8 guardado exitosamente!\n",
      "Archivos creados:\n",
      "- modelo_diagnostico_v8_reentrenado.pkl\n",
      "- preprocesadores_v8_reentrenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 8: GUARDAR MODELO REENTRENADO ---\n",
    "print(\">>> Guardando modelo reentrenado...\")\n",
    "\n",
    "try:\n",
    "    # Guardar modelo reentrenado\n",
    "    with open('models/modelo_diagnostico_v8_reentrenado.pkl', 'wb') as f:\n",
    "        pickle.dump(modelo_reentrenado, f)\n",
    "\n",
    "    # Guardar preprocesadores actualizados y mappings\n",
    "    with open('models/preprocesadores_v8_reentrenado.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'tfidf_vectorizer': tfidf_nuevo,\n",
    "            'age_encoder': age_encoder_nuevo,\n",
    "            'gender_encoder': gender_encoder_nuevo,\n",
    "            'diagnosis_encoder': diagnosis_encoder_nuevo,\n",
    "            'label_mapping': label_mapping,\n",
    "            'reverse_mapping': reverse_mapping,\n",
    "            'unique_labels': unique_labels\n",
    "        }, f)\n",
    "\n",
    "    print(\"✅ Modelo v8 guardado exitosamente!\")\n",
    "    print(\"Archivos creados:\")\n",
    "    print(\"- modelo_diagnostico_v8_reentrenado.pkl\")\n",
    "    print(\"- preprocesadores_v8_reentrenado.pkl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error guardando modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a5e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Función de predicción v8 creada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 9: FUNCIÓN DE PREDICCIÓN ACTUALIZADA ---\n",
    "def predecir_diagnostico_v8(texto_findings, edad_rango, genero_paciente):\n",
    "    \"\"\"\n",
    "    Función de predicción con modelo v8 reentrenado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocesar texto\n",
    "        texto_limpio = preprocess_text_advanced(texto_findings)\n",
    "        \n",
    "        # Vectorizar\n",
    "        texto_tfidf = tfidf_nuevo.transform([texto_limpio])\n",
    "        \n",
    "        # Validar y codificar categóricas\n",
    "        if edad_rango not in age_encoder_nuevo.classes_:\n",
    "            print(f\"Advertencia: Edad '{edad_rango}' no reconocida. Usando '31-40'.\")\n",
    "            edad_rango = \"31-40\"  # Valor por defecto común\n",
    "            \n",
    "        if genero_paciente not in gender_encoder_nuevo.classes_:\n",
    "            print(f\"Advertencia: Género '{genero_paciente}' no reconocido. Usando 'Male'.\")\n",
    "            genero_paciente = \"Male\"  # Valor por defecto\n",
    "            \n",
    "        edad_encoded = age_encoder_nuevo.transform([edad_rango])\n",
    "        genero_encoded = gender_encoder_nuevo.transform([genero_paciente])\n",
    "        \n",
    "        # Combinar características\n",
    "        caracteristicas_categoricas = np.array([[edad_encoded[0], genero_encoded[0]]])\n",
    "        caracteristicas_combinadas = hstack([texto_tfidf, caracteristicas_categoricas])\n",
    "        \n",
    "        # Predicción con etiquetas consecutivas\n",
    "        prediccion_consecutiva = modelo_reentrenado.predict(caracteristicas_combinadas)\n",
    "        probabilidades = modelo_reentrenado.predict_proba(caracteristicas_combinadas)\n",
    "        \n",
    "        # Convertir de etiquetas consecutivas a originales\n",
    "        prediccion_original = reverse_mapping[prediccion_consecutiva[0]]\n",
    "        \n",
    "        # Decodificar a nombre de enfermedad\n",
    "        categoria_predicha = diagnosis_encoder_nuevo.inverse_transform([prediccion_original])[0]\n",
    "        confianza = max(probabilidades[0]) * 100\n",
    "        \n",
    "        # Top 5 predicciones\n",
    "        top_indices = np.argsort(probabilidades[0])[::-1][:5]\n",
    "        top_categorias = []\n",
    "        for i in top_indices:\n",
    "            # Convertir índice consecutivo a etiqueta original\n",
    "            etiqueta_original = reverse_mapping[i]\n",
    "            categoria = diagnosis_encoder_nuevo.inverse_transform([etiqueta_original])[0]\n",
    "            prob = probabilidades[0][i] * 100\n",
    "            top_categorias.append({\n",
    "                \"disease\": categoria,\n",
    "                \"probability\": round(prob, 2)\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            'success': True,\n",
    "            'main_diagnosis': categoria_predicha,\n",
    "            'confidence': round(confianza, 2),\n",
    "            'top_predictions': top_categorias,\n",
    "            'processed_text': texto_limpio,\n",
    "            'model_version': 'v8_reentrenado'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'model_version': 'v8_reentrenado'\n",
    "        }\n",
    "\n",
    "print(\">>> Función de predicción v8 creada exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "662e11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Probando modelo v8 reentrenado...\n",
      "\n",
      "=== PRUEBAS DEL MODELO v8 ===\n",
      "\n",
      "--- CASO 1: Asma ---\n",
      "Predicción: Orthopedic/ Musculoskeletal\n",
      "Confianza: 17.809999465942383%\n",
      "Top 3 predicciones:\n",
      "  1. Orthopedic/ Musculoskeletal: 17.809999465942383%\n",
      "  2. Central Nervous System/ Neuromuscular: 17.760000228881836%\n",
      "  3. Mental: 9.520000457763672%\n",
      "❌ Predicción incorrecta\n",
      "\n",
      "--- CASO 2: Diabetes ---\n",
      "Predicción: Central Nervous System/ Neuromuscular\n",
      "Confianza: 19.3700008392334%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 19.3700008392334%\n",
      "  2. Orthopedic/ Musculoskeletal: 15.5600004196167%\n",
      "  3. Cancer: 8.210000038146973%\n",
      "❌ Predicción incorrecta\n",
      "\n",
      "--- CASO 3: Influenza ---\n",
      "Predicción: Central Nervous System/ Neuromuscular\n",
      "Confianza: 15.270000457763672%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 15.270000457763672%\n",
      "  2. Orthopedic/ Musculoskeletal: 14.529999732971191%\n",
      "  3. Mental: 8.180000305175781%\n",
      "❌ Predicción incorrecta\n",
      "\n",
      "--- CASO 4: Migraña ---\n",
      "Predicción: Central Nervous System/ Neuromuscular\n",
      "Confianza: 83.79000091552734%\n",
      "Top 3 predicciones:\n",
      "  1. Central Nervous System/ Neuromuscular: 83.79000091552734%\n",
      "  2. Skin: 4.380000114440918%\n",
      "  3. Digestive System/ Gastrointestinal: 3.809999942779541%\n",
      "❌ Predicción incorrecta\n",
      "\n",
      "--- CASO 5: Eczema ---\n",
      "Predicción: Skin\n",
      "Confianza: 39.16999816894531%\n",
      "Top 3 predicciones:\n",
      "  1. Skin: 39.16999816894531%\n",
      "  2. Central Nervous System/ Neuromuscular: 10.199999809265137%\n",
      "  3. Orthopedic/ Musculoskeletal: 9.350000381469727%\n",
      "❌ Predicción incorrecta\n",
      "\n",
      "📊 RESUMEN DE PRUEBAS:\n",
      "Casos correctos: 0/5\n",
      "Precisión en casos de prueba: 0.0%\n",
      "\n",
      ">>> ¡Modelo v8 reentrenado completado!\n",
      "📊 Precisión general: 75.18%\n",
      "🎯 Precisión en pruebas específicas: 0.0%\n",
      "🏥 Total enfermedades: 146\n",
      "🆕 Nuevas enfermedades añadidas: 116\n"
     ]
    }
   ],
   "source": [
    "# --- PASO 10: PRUEBAS DEL MODELO REENTRENADO ---\n",
    "print(\"\\n>>> Probando modelo v8 reentrenado...\")\n",
    "\n",
    "# Casos de prueba específicos del nuevo dataset\n",
    "casos_prueba_v8 = [\n",
    "    {\n",
    "        \"nombre\": \"Asma\",\n",
    "        \"symptoms\": \"Patient presents with cough, difficulty breathing, wheezing\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Male\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Diabetes\", \n",
    "        \"symptoms\": \"Patient reports fatigue, excessive thirst, frequent urination\",\n",
    "        \"age_range\": \"41-50\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Influenza\",\n",
    "        \"symptoms\": \"Patient presents with fever, cough, body aches, fatigue\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Migraña\",\n",
    "        \"symptoms\": \"Patient reports severe headache, sensitivity to light, nausea\",\n",
    "        \"age_range\": \"31-40\",\n",
    "        \"gender\": \"Female\"\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Eczema\",\n",
    "        \"symptoms\": \"Patient has skin rash, itching, dry skin patches\",\n",
    "        \"age_range\": \"21-30\",\n",
    "        \"gender\": \"Female\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n=== PRUEBAS DEL MODELO v8 ===\")\n",
    "aciertos = 0\n",
    "total_casos = len(casos_prueba_v8)\n",
    "\n",
    "for i, caso in enumerate(casos_prueba_v8, 1):\n",
    "    print(f\"\\n--- CASO {i}: {caso['nombre']} ---\")\n",
    "    \n",
    "    resultado = predecir_diagnostico_v8(\n",
    "        caso['symptoms'],\n",
    "        caso['age_range'], \n",
    "        caso['gender']\n",
    "    )\n",
    "    \n",
    "    if resultado['success']:\n",
    "        print(f\"Predicción: {resultado['main_diagnosis']}\")\n",
    "        print(f\"Confianza: {resultado['confidence']}%\")\n",
    "        print(\"Top 3 predicciones:\")\n",
    "        for j, pred in enumerate(resultado['top_predictions'][:3], 1):\n",
    "            print(f\"  {j}. {pred['disease']}: {pred['probability']}%\")\n",
    "        \n",
    "        # Verificar si la predicción es correcta\n",
    "        esperado = caso['nombre'].lower()\n",
    "        prediccion = resultado['main_diagnosis'].lower()\n",
    "        \n",
    "        # Buscar en predicción principal y top 3\n",
    "        encontrado = (esperado in prediccion or \n",
    "                     any(esperado in pred['disease'].lower() \n",
    "                         for pred in resultado['top_predictions'][:3]))\n",
    "        \n",
    "        if encontrado:\n",
    "            print(\"✅ Predicción CORRECTA\")\n",
    "            aciertos += 1\n",
    "        else:\n",
    "            print(\"❌ Predicción incorrecta\")\n",
    "    else:\n",
    "        print(f\"❌ Error: {resultado['error']}\")\n",
    "\n",
    "# Calcular precisión en casos de prueba\n",
    "precision_casos = (aciertos / total_casos) * 100\n",
    "print(f\"\\n📊 RESUMEN DE PRUEBAS:\")\n",
    "print(f\"Casos correctos: {aciertos}/{total_casos}\")\n",
    "print(f\"Precisión en casos de prueba: {precision_casos:.1f}%\")\n",
    "\n",
    "print(f\"\\n>>> ¡Modelo v8 reentrenado completado!\")\n",
    "print(f\"📊 Precisión general: {accuracy*100:.2f}%\")\n",
    "print(f\"🎯 Precisión en pruebas específicas: {precision_casos:.1f}%\")\n",
    "print(f\"🏥 Total enfermedades: {len(diagnosis_encoder_nuevo.classes_)}\")\n",
    "print(f\"🆕 Nuevas enfermedades añadidas: {len(nuevos_diagnosticos)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
